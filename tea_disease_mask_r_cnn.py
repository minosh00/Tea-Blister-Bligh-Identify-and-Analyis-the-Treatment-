# -*- coding: utf-8 -*-
"""Tea_Disease_Mask_R_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iAXxhXp4Hf9J5XowlAXSSmJtin7XBgPf

# Data cleaning
"""

from google.colab import drive
drive.mount('/content/drive')

"""### Create polygons from the binary images"""

import os

import cv2


input_dir = r'/content/drive/MyDrive/Tea Project Mask RCNN data/task_tea leaves-2023_09_26_20_15_41-segmentation mask 1.1.zip (Unzipped Files)/SegmentationClass'
output_dir = r'/content/drive/MyDrive/Tea Project Mask RCNN data/tea_leaves_lables'

for j in os.listdir(input_dir):
    image_path = os.path.join(input_dir, j)
    # load the binary mask and get its contours
    mask = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    _, mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)

    H, W = mask.shape
    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # convert the contours to polygons
    polygons = []
    for cnt in contours:
        if cv2.contourArea(cnt) > 200:
            polygon = []
            for point in cnt:
                x, y = point[0]
                polygon.append(x / W)
                polygon.append(y / H)
            polygons.append(polygon)

    # print the polygons
    with open('{}.txt'.format(os.path.join(output_dir, j)[:-4]), 'w') as f:
        for polygon in polygons:
            for p_, p in enumerate(polygon):
                if p_ == len(polygon) - 1:
                    f.write('{}\n'.format(p))
                elif p_ == 0:
                    f.write('0 {} '.format(p))
                else:
                    f.write('{} '.format(p))

        f.close()

"""### split the data in to train and test folders"""

import os
import shutil
import random

images_source_dir = r'/content/drive/MyDrive/Tea Project Mask RCNN data/Tea_blister_blight'
labels_source_dir = r'/content/drive/MyDrive/Tea Project Mask RCNN data/tea_leaves_lables'
output_dir = r'/content/drive/MyDrive/Tea Project Mask RCNN data/dataset'


os.makedirs(os.path.join(output_dir, 'images', 'train'), exist_ok=True)
os.makedirs(os.path.join(output_dir, 'images', 'val'), exist_ok=True)
os.makedirs(os.path.join(output_dir, 'labels', 'train'), exist_ok=True)
os.makedirs(os.path.join(output_dir, 'labels', 'val'), exist_ok=True)

image_files = os.listdir(images_source_dir)
label_files = os.listdir(labels_source_dir)


image_files.sort()
label_files.sort()


random.seed(42)
random.shuffle(image_files)
split_index = int(0.8 * len(image_files))


train_image_files = image_files[:split_index]
val_image_files = image_files[split_index:]


for image_file in train_image_files:
    shutil.copy(os.path.join(images_source_dir, image_file), os.path.join(output_dir, 'images', 'train', image_file))
for image_file in val_image_files:
    shutil.copy(os.path.join(images_source_dir, image_file), os.path.join(output_dir, 'images', 'val', image_file))


for image_file in train_image_files:
    label_file = image_file.replace('.jpg', '.txt')  # Assuming labels have the same name with a .txt extension
    shutil.copy(os.path.join(labels_source_dir, label_file), os.path.join(output_dir, 'labels', 'train', label_file))
for image_file in val_image_files:
    label_file = image_file.replace('.jpg', '.txt')  # Assuming labels have the same name with a .txt extension
    shutil.copy(os.path.join(labels_source_dir, label_file), os.path.join(output_dir, 'labels', 'val', label_file))

print("Splitting completed.")

"""# Model training

### yolo model implementation
"""

!pip install ultralytics

from ultralytics import YOLO

model = YOLO('yolov8n-seg.pt')
model.train(data=r'/content/drive/MyDrive/Tea Project Mask RCNN data/config.yaml', epochs=50, imgsz=640)

import locale
def getpreferredencoding(do_setlocale = True):
    return "UTF-8"
locale.getpreferredencoding = getpreferredencoding

!scp -r /content/runs '/content/drive/MyDrive/Tea Project Mask RCNN data/result'

"""### Run inference

"""

from ultralytics import YOLO

import cv2

model_path = r'/content/drive/MyDrive/Tea Project Mask RCNN data/results/runs/segment/train2/weights/best.pt'
image_path = r'/content/drive/MyDrive/Tea Project Mask RCNN data/Tea_blister_blight/20230626_150350 (1) - Copy.jpg'

img = cv2.imread(image_path)
H, W, _ = img.shape

model = YOLO(model_path)
results = model(img , save=True)
# print(results[0].masks.data)

from google.colab.patches import cv2_imshow
import numpy as np

for result in results:
    for j, mask in enumerate(result.masks.data):
        mask = mask.cpu().numpy() * 255
        mask = cv2.resize(mask, (W, H), interpolation=cv2.INTER_LINEAR)

        # Find contours in the mask
        contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # Iterate through the contours and crop the regions of interest
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            cropped_img = img[y:y+h, x:x+w]
            cv2.imwrite(r"/content/cropped.png", cropped_img)
            cv2_imshow(cropped_img)
            cv2.waitKey(0)

cv2.destroyAllWindows()

# Iterate through the results
for result in results:
    for j, mask in enumerate(result.masks.data):
        mask = mask.cpu().numpy() * 255
        mask = cv2.resize(mask, (img.shape[1], img.shape[0]), interpolation=cv2.INTER_LINEAR)

        # Find contours in the mask
        contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # Iterate through the contours and create a mask for each segmented region
        for contour in contours:
            # Create a mask for the current contour
            mask_region = np.zeros_like(mask)
            cv2.drawContours(mask_region, [contour], 0, 255, thickness=cv2.FILLED)

            # Convert both the image and mask to the same data type (CV_8U)
            img = img.astype(np.uint8)
            mask_region = mask_region.astype(np.uint8)

            # Use the mask to extract the segmented region from the original image
            segmented_region = cv2.bitwise_and(img, img, mask=mask_region)
            output_path = r"/content/result.png"
            segmented_region = cv2.resize(segmented_region, (400, 400))
            cv2.imwrite(output_path, segmented_region)
            cv2.waitKey(0)

cv2.destroyAllWindows()

"""### kmean clustering"""

import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
from sklearn import cluster
import random

def image_to_array(image_path):
  image_array = np.array(PIL.Image.open(image_path))
  print("image_size" , image_array.shape)
  height = image_array.shape[0]
  width = image_array.shape[1]
  band = image_array.shape[2]
  numpy_array = image_array.reshape(-1 , band)
  return height , width , numpy_array

class_n = 10
height , width , x = image_to_array("/content/result.png")
k_means = cluster.KMeans(class_n)
k_means.fit(x)

k_means_model = k_means

def prediction_model(image_path):
  original_image = PIL.Image.open(r"/content/runs/segment/predict2/image0.jpg")
  cropped_image = PIL.Image.open(r"/content/cropped.png")
  new_height, new_width, new_x = image_to_array(image_path)

  new_labels = k_means_model.predict(new_x)
  cluster_counts = np.bincount(new_labels)  # Count the number of pixels in each cluster
  total_pixels = new_height * new_width
  percentage_pixels = cluster_counts / total_pixels * 100

  for i, percentage in enumerate(percentage_pixels):
    print(i , percentage)



  x_classified = new_labels
  result = x_classified.reshape(new_height , new_width )
  plt.figure(figsize=(15,5))
  cmap = plt.get_cmap("jet" , np.max(result)-np.min(result) +1)

  plt.subplot(1 ,4, 1)
  plt.imshow(original_image)

  plt.subplot(1, 4, 2)  # Additional Image
  plt.imshow(cropped_image)

  plt.subplot(1 ,4 , 3)
  plt.imshow(new_x.reshape(new_height , new_width , 3))

  plt.subplot(1, 4,4)
  plt.imshow(result , cmap=cmap)

  cax = plt.axes([1.01, 0.125, 0.025, 0.75])
  plt.colorbar(cax=cax)
  plt.show()

prediction_model("/content/result.png")

import numpy as np
import PIL
import cv2
import matplotlib.pyplot as plt

def image_to_array(image_path):
    image_array = np.array(PIL.Image.open(image_path))
    print("image_size", image_array.shape)
    height, width, band = image_array.shape
    numpy_array = image_array.reshape(-1, band)
    return height, width, numpy_array

def binary_segmentation(image_path, threshold_value):
    height, width, x = image_to_array(image_path)

    # Convert to grayscale
    gray_image = cv2.cvtColor(x.reshape(height, width, 3), cv2.COLOR_RGB2GRAY)

    # Apply thresholding
    _, binary_mask = cv2.threshold(gray_image, threshold_value, 255, cv2.THRESH_BINARY)

    # Perform post-processing if needed
    # binary_mask = cv2.erode(binary_mask, kernel, iterations=1)
    # binary_mask = cv2.dilate(binary_mask, kernel, iterations=1)

    return height, width, binary_mask

def visualize_binary_mask(image_path, threshold_value):
    height, width, binary_mask = binary_segmentation(image_path, threshold_value)

    original_image = np.array(PIL.Image.open(image_path))  # Convert to NumPy array

    # Create a colored overlay
    overlay = np.zeros_like(original_image)

    # Assign colors to healthy and diseased areas
    overlay[binary_mask == 0] = [0, 255, 0]  # Green for healthy areas
    overlay[binary_mask > 0] = [255, 0, 0]  # Red for diseased areas

    # Combine the overlay and the original image
    segmented_image = cv2.addWeighted(original_image, 0.7, overlay, 0.3, 0)

    plt.figure(figsize=(12, 12))

    plt.subplot(1, 2, 1)  # Original Image
    plt.imshow(original_image)

    plt.subplot(1, 2, 2)  # Segmented Image
    plt.imshow(segmented_image)

    plt.show()

# Adjust the threshold value as needed
threshold_value = 130
image_path = "/content/result.png"
visualize_binary_mask(image_path, threshold_value)